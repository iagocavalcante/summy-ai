import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import OpenAI from 'openai';
import {
  LLMAdapter,
  LLMResponse,
  LLMStreamChunk,
} from '../interfaces/llm-adapter.interface';

@Injectable()
export class OpenAIAdapter implements LLMAdapter {
  private readonly logger = new Logger(OpenAIAdapter.name);
  private openai: OpenAI | null = null;
  private readonly timeout = 60000; // 60 seconds
  private readonly maxRetries = 3;

  constructor(private configService: ConfigService) {
    const apiKey = this.configService.get<string>('OPENAI_API_KEY');
    if (apiKey) {
      try {
        this.openai = new OpenAI({
          apiKey,
          timeout: this.timeout,
          maxRetries: this.maxRetries,
        });
        this.logger.log('OpenAI adapter initialized successfully');
      } catch (error) {
        this.logger.error('Failed to initialize OpenAI adapter', error);
      }
    } else {
      this.logger.warn('OPENAI_API_KEY not configured');
    }
  }

  getProviderName(): string {
    return 'openai';
  }

  isAvailable(): boolean {
    return !!this.openai;
  }

  private getSystemPrompt(): string {
    return `You are an AI summarization assistant that specializes in creating clear, concise summaries from text blocks. Your primary goal is to extract key information and present it in well-formatted markdown.

**YOUR MAIN PURPOSE:**
- Transform articles, meeting notes, emails, and documents into digestible summaries
- Extract key points, main ideas, and actionable items
- Present information in a structured, easy-to-read format

**FORMATTING REQUIREMENTS:**
- Use headings: # Main Summary, ## Key Points, ### Details, #### Action Items
- Format text: **bold** for key terms, *italic* for emphasis
- Use \`inline code\` for technical terms, file names, or specific values
- Create proper markdown lists with line breaks:
  * Use "- " (dash + space) for bullet points, each on a new line
  * Use "1. " (number + dot + space) for numbered lists, each on a new line
  * Always add blank lines before and after lists
- Use > blockquotes for important quotes or critical information
- Create tables with | headers | data | when organizing structured data
- Add horizontal rules --- to separate major sections

**CRITICAL LIST FORMATTING RULES:**
- Each bullet point MUST start on a new line with "- " (dash + space)
- Each numbered item MUST start on a new line with "1. ", "2. ", etc.
- Never put multiple list items on the same line
- Always add a blank line before and after any list
- Example of CORRECT bullet formatting:

## Key Points

- First key point goes here with proper spacing
- Second key point on its own line
- Third key point also on its own line

## Details

1. First numbered item
2. Second numbered item
3. Third numbered item

**SUMMARY STRUCTURE:**
1. **# Summary** - Start with a clear title describing the content type
2. **## Key Points** - Extract 3-5 main takeaways using bullet points
3. **## Details** - Provide supporting information in subsections as needed
4. **## Action Items** (if applicable) - List any tasks, decisions, or next steps
5. **## Conclusion** - Brief wrap-up of the most important information

**CONTENT HANDLING:**
- For **articles**: Focus on main arguments, findings, and conclusions
- For **meeting notes**: Highlight decisions made, action items, and key discussions
- For **emails**: Summarize purpose, requests, deadlines, and required responses
- For **documents**: Extract core concepts, important data, and recommendations

**FINAL FORMATTING REMINDER:**
Always format your response using proper markdown syntax:
- Start each bullet point with "- " on a new line
- Add blank lines before and after lists
- Use proper heading hierarchy (# ## ### ####)
- Make text scannable and well-structured`;
  }

  async summarize(text: string): Promise<LLMResponse> {
    if (!this.openai) {
      const error = new Error(
        'OpenAI client not initialized. Check OPENAI_API_KEY.',
      );
      this.logger.error(error.message);
      throw error;
    }

    if (!text || text.trim().length === 0) {
      throw new Error('Text cannot be empty');
    }

    try {
      const completion = await this.openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: [
          {
            role: 'system',
            content: this.getSystemPrompt(),
          },
          {
            role: 'user',
            content: `Please provide a well-formatted markdown summary of the following content:\n\n${text}`,
          },
        ],
        temperature: 0.3,
        max_tokens: 1000,
      });

      const summary = completion.choices[0]?.message?.content;
      if (!summary) {
        throw new Error('No summary generated by OpenAI');
      }

      return {
        text: summary,
        tokensInput: completion.usage?.prompt_tokens,
        tokensOutput: completion.usage?.completion_tokens,
        model: completion.model,
        provider: 'openai',
      };
    } catch (error) {
      this.logger.error('Error in OpenAI summarize', {
        error: error instanceof Error ? error.message : 'Unknown error',
        textLength: text.length,
      });
      throw error;
    }
  }

  async *summarizeStream(text: string): AsyncGenerator<LLMStreamChunk> {
    if (!this.openai) {
      const error = new Error(
        'OpenAI client not initialized. Check OPENAI_API_KEY.',
      );
      this.logger.error(error.message);
      throw error;
    }

    if (!text || text.trim().length === 0) {
      throw new Error('Text cannot be empty');
    }

    try {
      const stream = await this.openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: [
          {
            role: 'system',
            content: this.getSystemPrompt(),
          },
          {
            role: 'user',
            content: `Please provide a well-formatted markdown summary of the following content:\n\n${text}`,
          },
        ],
        stream: true,
        temperature: 0.3,
        max_tokens: 1000,
      });

      let hasContent = false;
      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || '';
        if (content) {
          hasContent = true;
          yield {
            text: content,
            done: false,
          };
        }
      }

      if (!hasContent) {
        throw new Error('No content streamed from OpenAI');
      }

      yield {
        text: '',
        done: true,
      };
    } catch (error) {
      this.logger.error('Error in OpenAI stream', {
        error: error instanceof Error ? error.message : 'Unknown error',
        textLength: text.length,
      });
      throw error;
    }
  }
}
